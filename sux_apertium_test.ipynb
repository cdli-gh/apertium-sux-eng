{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import subprocess\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "apertium_mt_path = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_file_read(filename):\n",
    "    lines=[]\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            line=line.strip()\n",
    "            lines.append(line)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_machine_translation(sux_sentence,eng_tranlation_reference):\n",
    "    sux_sentence = sux_sentence.replace(':','-').replace('(','\\(').replace(')','\\)').replace(\"'\",\"\\\\'\").replace('|','\\|')\n",
    "    apertium_translation_command = f'''echo {sux_sentence} | apertium -d {apertium_mt_path} sux-eng'''\n",
    "    output = subprocess.check_output(apertium_translation_command, shell=True)\n",
    "    output = output.decode('ascii').strip().replace('#','').replace('-',' ').replace('*',' ').split()\n",
    "\n",
    "    return \" \".join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_machine_translation(sux_sentence,eng_tranlation_reference):\n",
    "    return eng_tranlation_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P320163.conll',\n",
       " 'P125272.conll',\n",
       " 'P416458.conll',\n",
       " 'P107372.conll',\n",
       " 'P101172.conll',\n",
       " 'P203075.conll',\n",
       " 'P108689.conll',\n",
       " 'P206146.conll',\n",
       " 'P118757.conll',\n",
       " 'P209503.conll',\n",
       " 'P432333.conll',\n",
       " 'P273892.conll',\n",
       " 'P432157.conll',\n",
       " 'P107130.conll',\n",
       " 'P107369.conll',\n",
       " 'P432372.conll',\n",
       " 'P134336.conll',\n",
       " 'P361739.conll',\n",
       " 'P432116.conll',\n",
       " 'P332170.conll',\n",
       " 'P407068.conll',\n",
       " 'P470071.conll',\n",
       " 'P331046.conll',\n",
       " 'P467836.conll',\n",
       " 'P340847.conll',\n",
       " 'P316855.conll',\n",
       " 'P315822.conll',\n",
       " 'P424392.conll',\n",
       " 'P411977.conll',\n",
       " 'P432188.conll',\n",
       " 'P430147.conll',\n",
       " 'P208745.conll',\n",
       " 'P137383.conll',\n",
       " 'P116255.conll',\n",
       " 'P204646.conll',\n",
       " 'P432290.conll',\n",
       " 'P113323.conll',\n",
       " 'P432335.conll',\n",
       " 'P107128.conll',\n",
       " 'P432353.conll',\n",
       " 'P331043.conll',\n",
       " 'P130219.conll',\n",
       " 'P212352.conll',\n",
       " 'P205148.conll',\n",
       " 'P370955.conll',\n",
       " 'P108651.conll',\n",
       " 'P100765.conll',\n",
       " 'P127326.conll',\n",
       " 'P432169.conll',\n",
       " 'P432268.conll',\n",
       " 'P458725.conll',\n",
       " 'P111481.conll',\n",
       " 'P142051.conll',\n",
       " 'P430412.conll',\n",
       " 'P465776.conll',\n",
       " 'P416464.conll',\n",
       " 'P432135.conll',\n",
       " 'P455868.conll',\n",
       " 'P465383.conll',\n",
       " 'P432209.conll',\n",
       " 'P113918.conll',\n",
       " 'P416459.conll',\n",
       " 'P458780.conll',\n",
       " 'P482028.conll',\n",
       " 'P416425.conll',\n",
       " 'P112536.conll',\n",
       " 'P430186.conll',\n",
       " 'P458721.conll',\n",
       " 'P205914.conll',\n",
       " 'P133314.conll',\n",
       " 'P110972.conll',\n",
       " 'P204991.conll',\n",
       " 'P115087.conll',\n",
       " 'P127488.conll',\n",
       " 'P290815.conll',\n",
       " 'P131770.conll',\n",
       " 'P432117.conll',\n",
       " 'P424375.conll',\n",
       " 'P111037.conll',\n",
       " 'P108041.conll',\n",
       " 'P101274.conll',\n",
       " 'P430521.conll',\n",
       " 'P100179.conll',\n",
       " 'P432323.conll',\n",
       " 'P430354.conll',\n",
       " 'P432203.conll',\n",
       " 'P206257.conll',\n",
       " 'P112564.conll',\n",
       " 'P209340.conll',\n",
       " 'P101263.conll',\n",
       " 'P110943.conll',\n",
       " 'P340460.conll',\n",
       " 'P133045.conll',\n",
       " 'P430486.conll',\n",
       " 'P416491.conll',\n",
       " 'P432240.conll',\n",
       " 'P273416.conll',\n",
       " 'P102524.conll',\n",
       " 'P111531.conll',\n",
       " 'P340525.conll',\n",
       " 'P416409.conll',\n",
       " 'P204752.conll',\n",
       " 'P432259.conll',\n",
       " 'P458570.conll',\n",
       " 'P469660.conll',\n",
       " 'P432221.conll',\n",
       " 'P430466.conll',\n",
       " 'P345966.conll',\n",
       " 'P416473.conll',\n",
       " 'P206336.conll',\n",
       " 'P405991.conll',\n",
       " 'P430645.conll',\n",
       " 'P203299.conll',\n",
       " 'P138100.conll',\n",
       " 'P142796.conll',\n",
       " 'P458732.conll',\n",
       " 'P143960.conll',\n",
       " 'P430134.conll',\n",
       " 'P416457.conll',\n",
       " 'P432125.conll',\n",
       " 'P424387.conll',\n",
       " 'P111448.conll',\n",
       " 'P416399.conll',\n",
       " 'P202818.conll',\n",
       " 'P102335.conll',\n",
       " 'P101286.conll',\n",
       " 'P315976.conll',\n",
       " 'P458650.conll',\n",
       " 'P114895.conll',\n",
       " 'P109995.conll',\n",
       " 'P416415.conll',\n",
       " 'P116240.conll',\n",
       " 'P107220.conll',\n",
       " 'P458027.conll',\n",
       " 'P458737.conll',\n",
       " 'P107495.conll',\n",
       " 'P427603.conll',\n",
       " 'P470064.conll',\n",
       " 'P432162.conll',\n",
       " 'P432127.conll',\n",
       " 'P209263.conll',\n",
       " 'P429958.conll',\n",
       " 'P204751.conll',\n",
       " 'P424381.conll',\n",
       " 'P432267.conll',\n",
       " 'P382205.conll',\n",
       " 'P319075.conll',\n",
       " 'P480699.conll',\n",
       " 'P458818.conll',\n",
       " 'P205489.conll',\n",
       " 'P432239.conll',\n",
       " 'P430353.conll',\n",
       " 'P432140.conll',\n",
       " 'P118388.conll',\n",
       " 'P380029.conll',\n",
       " 'P101266.conll',\n",
       " 'P416408.conll']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path = 'data/consolidated/dev'\n",
    "file_name = os.listdir(dir_path)\n",
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Hard limit of 500 cohorts reached at cohort \"<ki>\" (#499) on line 0 - forcing break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Hard limit of 500 cohorts reached at cohort \"<i3-nun>\" (#499) on line 0 - forcing break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156\n",
      "157\n",
      "\n",
      " average bleu score for rule based is - 6.244483513924998\n"
     ]
    }
   ],
   "source": [
    "translation_data = []\n",
    "count=0\n",
    "sum_rule_bleu = 0\n",
    "sum_nn_bleu = 0\n",
    "chencherry = SmoothingFunction()\n",
    "\n",
    "\n",
    "for file in file_name:\n",
    "    count+=1\n",
    "    print(count)\n",
    "\n",
    "    file_path = os.path.join(dir_path,file)\n",
    "    file_data = txt_file_read(file_path)\n",
    "\n",
    "    # extracting sumerian and english translation from the file\n",
    "    sux_sentence = ''\n",
    "    for row in file_data:\n",
    "        if row.startswith('# tr.en'):\n",
    "            eng_tranlation_reference = row.split('tr.en:')[1]\n",
    "        row_line = row.split('\\t')\n",
    "        if row_line[0].isdigit() and 'XPOSTAG' not in row:\n",
    "            sux_sentence+=row_line[1]+' '\n",
    "\n",
    "    # basic cleaning of english reference sentence so we do not miss correct words match because of basic errors like (Su-zen same as Suzen and suzen same as suzen)\n",
    "    eng_tranlation_reference = eng_tranlation_reference.replace('-','').lower()\n",
    "\n",
    "    # basic cleaning of sumerian sentence before passing to rulebased translation\n",
    "    sux_sentence = sux_sentence.replace('<','').replace('>','').lower()\n",
    "\n",
    "\n",
    "    #================================ Machine Translation ================================================ #\n",
    "\n",
    "\n",
    "    eng_rule_based_translation = rule_machine_translation(sux_sentence,eng_tranlation_reference)\n",
    "    rule_bleu = sentence_bleu([eng_tranlation_reference.split()], eng_rule_based_translation.split(),smoothing_function=chencherry.method1,weights = (0.75,0.25,0,0))*100\n",
    "    sum_rule_bleu += rule_bleu\n",
    "    avg_rule_bleu = sum_rule_bleu/count \n",
    "\n",
    "    eng_nn_based_translation = nn_machine_translation(sux_sentence,eng_tranlation_reference)\n",
    "    nn_bleu = sentence_bleu([eng_tranlation_reference.split()], eng_nn_based_translation.split(), smoothing_function=chencherry.method1, weights = (0.75,0.25,0,0))*100\n",
    "    sum_nn_bleu += nn_bleu\n",
    "    avg_nn_bleu = sum_nn_bleu/count \n",
    "\n",
    "    translation_data.append([file, sux_sentence, eng_tranlation_reference, eng_rule_based_translation, eng_nn_based_translation, rule_bleu, nn_bleu])\n",
    "\n",
    "    # if count==33:\n",
    "    #     break\n",
    "\n",
    "print(f'''\\n average bleu score for rule based is - {avg_rule_bleu}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = ['file', 'sux_sentence', 'eng_tranlation_reference', 'eng_rule_based_translation', 'eng_nn_based_translation', 'rule_bleu', 'nn_bleu']\n",
    "trainslation_pd = pd.DataFrame(translation_data,columns = col_name)\n",
    "trainslation_pd.to_csv('translation_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>sux_sentence</th>\n",
       "      <th>eng_tranlation_reference</th>\n",
       "      <th>eng_rule_based_translation</th>\n",
       "      <th>eng_nn_based_translation</th>\n",
       "      <th>rule_bleu</th>\n",
       "      <th>nn_bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P320163.conll</td>\n",
       "      <td>pisan-dub-ba mu 2(disz) sze-ba giri3-se3-ga ug...</td>\n",
       "      <td>basketoftablets years of rations personnel of...</td>\n",
       "      <td>archivist name one ration attendant ugnim{ pla...</td>\n",
       "      <td>basketoftablets years of rations personnel of...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P125272.conll</td>\n",
       "      <td>usz2 ur-sila-luh 1(asz@c) gan2 e2-ur2-bi-du10 ...</td>\n",
       "      <td>dead ursilalu ac field eurbidu a foreman ac f...</td>\n",
       "      <td>he dead ur unit luh 1( asz@ c) gan2 E'urbidu o...</td>\n",
       "      <td>dead ursilalu ac field eurbidu a foreman ac f...</td>\n",
       "      <td>6.754154</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P416458.conll</td>\n",
       "      <td>4(disz) ki szu-{d}idim-ta mu-kux(du) iti ezem-...</td>\n",
       "      <td>oxen cows male equids female equids old from ...</td>\n",
       "      <td>one place hand { d} idim unknown name kux(he g...</td>\n",
       "      <td>oxen cows male equids female equids old from ...</td>\n",
       "      <td>2.645627</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P107372.conll</td>\n",
       "      <td>pisan-dub-ba kiszib3 didli masz-x-x e2 lu2-gi-...</td>\n",
       "      <td>basketoftablets sealed documents varied from ...</td>\n",
       "      <td>archivist seal he several goat _ house Lugina ...</td>\n",
       "      <td>basketoftablets sealed documents varied from ...</td>\n",
       "      <td>4.413135</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P101172.conll</td>\n",
       "      <td>5(disz) sila3 kasz saga 5(disz) sila3 ninda 5(...</td>\n",
       "      <td>sila fine beer sila bread shekels onions shek...</td>\n",
       "      <td>one unit beer he good one unit bread one unit ...</td>\n",
       "      <td>sila fine beer sila bread shekels onions shek...</td>\n",
       "      <td>8.348981</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            file                                       sux_sentence  \\\n",
       "0  P320163.conll  pisan-dub-ba mu 2(disz) sze-ba giri3-se3-ga ug...   \n",
       "1  P125272.conll  usz2 ur-sila-luh 1(asz@c) gan2 e2-ur2-bi-du10 ...   \n",
       "2  P416458.conll  4(disz) ki szu-{d}idim-ta mu-kux(du) iti ezem-...   \n",
       "3  P107372.conll  pisan-dub-ba kiszib3 didli masz-x-x e2 lu2-gi-...   \n",
       "4  P101172.conll  5(disz) sila3 kasz saga 5(disz) sila3 ninda 5(...   \n",
       "\n",
       "                            eng_tranlation_reference  \\\n",
       "0   basketoftablets years of rations personnel of...   \n",
       "1   dead ursilalu ac field eurbidu a foreman ac f...   \n",
       "2   oxen cows male equids female equids old from ...   \n",
       "3   basketoftablets sealed documents varied from ...   \n",
       "4   sila fine beer sila bread shekels onions shek...   \n",
       "\n",
       "                          eng_rule_based_translation  \\\n",
       "0  archivist name one ration attendant ugnim{ pla...   \n",
       "1  he dead ur unit luh 1( asz@ c) gan2 E'urbidu o...   \n",
       "2  one place hand { d} idim unknown name kux(he g...   \n",
       "3  archivist seal he several goat _ house Lugina ...   \n",
       "4  one unit beer he good one unit bread one unit ...   \n",
       "\n",
       "                            eng_nn_based_translation  rule_bleu  nn_bleu  \n",
       "0   basketoftablets years of rations personnel of...   0.000000    100.0  \n",
       "1   dead ursilalu ac field eurbidu a foreman ac f...   6.754154    100.0  \n",
       "2   oxen cows male equids female equids old from ...   2.645627    100.0  \n",
       "3   basketoftablets sealed documents varied from ...   4.413135    100.0  \n",
       "4   sila fine beer sila bread shekels onions shek...   8.348981    100.0  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainslation_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exrta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = os.system(f'''echo \"e2 lugal-la mu-un-du3\" | apertium -d apertium-sux-eng/ sux-eng''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sux_sentence = \"pisan-dub-ba dub gid2-da i3-dub giri3 ku5-da-mu i3-gal2 mu si-mu-ru-um{ki} lu-lu-bu{ki} <a>-ra2 1(u) la2 1(disz)-kam-asz ba-hul\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pisan-dub-ba dub gid2-da i3-dub giri3 ku5-da-mu i3-gal2 mu si-mu-ru-um{ki} lu-lu-bu{ki} a-ra2 1(u) la2 1(disz)-kam-asz ba-hul'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sux_sentence = sux_sentence.replace('<','').replace('>','')\n",
    "sux_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'archivist tablet he drag granary foot Kudamu he be in name Simurrum Lulubu times ten he hang one asz he _'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sux_sentence = sux_sentence.replace(':','-').replace('(','\\(').replace(')','\\)').replace(\"'\",\"\\\\'\").replace('|','\\|')\n",
    "apertium_translation_command = f'''echo {sux_sentence} | apertium -d . sux-eng'''\n",
    "output = subprocess.check_output(apertium_translation_command, shell=True)\n",
    "output = output.decode('ascii').strip().replace('#','').replace('-',' ').replace('*',' ').split()\n",
    "\" \".join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK BlEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reference = [['this','boy']]\n",
    "candidate = ['this', 'is']\n",
    "chencherry = SmoothingFunction()\n",
    "score = sentence_bleu(reference, candidate, smoothing_function=chencherry.method1, weights=(1,0,0,0))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_bleu([eng_tranlation_reference.split()], eng_nn_based_translation.split(), smoothing_function=chencherry.method1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huggingface evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/gsoc/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.0, 'counts': [2, 1, 0, 0], 'totals': [2, 1, 0, 0], 'precisions': [100.0, 100.0, 0.0, 0.0], 'bp': 1.0, 'sys_len': 2, 'ref_len': 2}\n"
     ]
    }
   ],
   "source": [
    "predictions = [\"hello there\"]\n",
    "references = [\n",
    "     [\"hello bro\"],\n",
    " ]\n",
    "bleu = evaluate.load(\"sacrebleu\")\n",
    "results = bleu.compute(predictions=predictions, references=references, smooth_method= 'floor')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [\"hello\"]\n",
    "references = [[\"hello there\"]]\n",
    "sacrebleu = evaluate.load(\"sacrebleu\")\n",
    "results = sacrebleu.compute(predictions=predictions, \n",
    "                             references=references, smooth_method = 'add-k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 36.78794411714425,\n",
       " 'counts': [1, 1, 1, 1],\n",
       " 'totals': [1, 1, 1, 1],\n",
       " 'precisions': [100.0, 100.0, 100.0, 100.0],\n",
       " 'bp': 0.36787944117144233,\n",
       " 'sys_len': 1,\n",
       " 'ref_len': 2}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('gsoc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b2059aca115e59cd7c84b0223fc0dde900163694b67bbfbf2e88c019072cf6f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
